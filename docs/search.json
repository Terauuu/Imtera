[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ethan An",
    "section": "",
    "text": "current\nOperation | Eastwest Bank\nMaster of business analytics | Rady school of management"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Ethan’s project",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nEthan An\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Resume",
    "section": "",
    "text": "Last update 2024_06_01\nDownload PDF file."
  },
  {
    "objectID": "project/hw1/hw1_questions.html",
    "href": "project/hw1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nTo better understand how pricing mechanisms affect charitable giving, Karlan and List implemented a large-scale natural field experiment involving over 50,000 prior donors to a politically active nonprofit organization. Participants were randomly assigned to one of several groups:\n\nA control group, receiving a standard fundraising letter with no mention of a match.\nOne or more treatment groups, receiving letters offering a matching grant of varying ratios—$1:$1, $2:$1, or $3:$1.\nEach treatment also varied the maximum matching amount (e.g., $25,000 or $100,000), and suggested donation levels (based on prior donations).\n\nThis experimental design allowed the researchers to isolate the causal effect of matching offers—both their presence and their generosity—on the likelihood of donating and the amount donated. It also enabled an exploration of how political context might moderate these effects.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "project/hw1/hw1_questions.html#introduction",
    "href": "project/hw1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nTo better understand how pricing mechanisms affect charitable giving, Karlan and List implemented a large-scale natural field experiment involving over 50,000 prior donors to a politically active nonprofit organization. Participants were randomly assigned to one of several groups:\n\nA control group, receiving a standard fundraising letter with no mention of a match.\nOne or more treatment groups, receiving letters offering a matching grant of varying ratios—$1:$1, $2:$1, or $3:$1.\nEach treatment also varied the maximum matching amount (e.g., $25,000 or $100,000), and suggested donation levels (based on prior donations).\n\nThis experimental design allowed the researchers to isolate the causal effect of matching offers—both their presence and their generosity—on the likelihood of donating and the amount donated. It also enabled an exploration of how political context might moderate these effects.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "project/hw1/hw1_questions.html#data",
    "href": "project/hw1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\nWe load the dataset provided by Karlan and List (2007), which contains responses from over 50,000 previous donors who were randomly assigned to receive different versions of a fundraising letter. The dataset includes treatment assignments (e.g., control vs. matching grant groups), donation outcomes, and demographic/political context data.\nThe data has 50,083 observations and 51 variables. Some of the key variables include:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nfrom scipy import stats\nimport pandas as pd\n\ntreated = df[df[\"treatment\"] == 1]\ncontrol = df[df[\"control\"] == 1]\n\nvars_to_test = [\"years\", \"freq\", \"mrm2\", \"female\", \"couple\"]\nbalance_table = []\n\nfor var in vars_to_test:\n    t_mean = treated[var].mean()\n    c_mean = control[var].mean()\n    t_stat, p_val = stats.ttest_ind(treated[var].dropna(), control[var].dropna(), equal_var=False)\n    balance_table.append((var, round(c_mean, 2), round(t_mean, 2), round(p_val, 4)))\n\npd.DataFrame(balance_table, columns=[\"Variable\", \"Control Mean\", \"Treatment Mean\", \"p-value\"])\n\n\n\n\n\n\n\nVariable\nControl Mean\nTreatment Mean\np-value\n\n\n\n\n0\nyears\n6.14\n6.08\n0.2753\n\n\n1\nfreq\n8.05\n8.04\n0.9117\n\n\n2\nmrm2\n13.00\n13.01\n0.9049\n\n\n3\nfemale\n0.28\n0.28\n0.0795\n\n\n4\ncouple\n0.09\n0.09\n0.5604\n\n\n\n\n\nBased on the p-values, we observe that none of the variables differ significantly between the two groups at the 5% level. This supports the notion that random assignment was successful and that the treatment and control groups are statistically balanced at baseline.\nTo confirm this, we also fit a simple linear regression model: ### Regression: Effect of Treatment on Prior Giving Behavior\nWe use a linear regression to test whether prior donation behavior (mrm2) differs across treatment groups. This serves as a balance check for the experimental design.\n\nimport pyrsm as rsm\n\nreg = rsm.model.regress(\n    data={\"df\": df},\n    rvar=\"mrm2\",\n    evar=\"treatment\"\n)\n\nreg.summary()\n\nThe regression output is summarized in the following screenshot:\n\n\n\nRegression output\n\n\nThe treatment coefficient is small (0.014) and statistically insignificant (p = 0.905), indicating that the treatment and control groups were well balanced in terms of prior maximum donations.\nThis supports the validity of the random assignment mechanism."
  },
  {
    "objectID": "project/hw1/hw1_questions.html#experimental-results",
    "href": "project/hw1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\ndonation_rate = df.groupby(\"treatment\")[\"gave\"].mean().rename({0: \"Control\", 1: \"Treatment\"})\n\ndonation_rate.plot(kind=\"bar\", color=[\"gray\", \"steelblue\"], edgecolor=\"black\")\nplt.title(\"Donation Rate by Treatment Group\")\nplt.ylabel(\"Proportion Donated\")\nplt.ylim(0, 0.03)\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\n\ntreated = df[df[\"treatment\"] == 1][\"gave\"]\ncontrol = df[df[\"treatment\"] == 0][\"gave\"]\n\nt_stat, p_val = ttest_ind(treated, control, equal_var=False)\nprint(f\"T-statistic = {t_stat:.3f}, p-value = {p_val:.4f}\")\n\nT-statistic = 3.209, p-value = 0.0013\n\n\n\nimport pyrsm as rsm\n\nreg = rsm.model.regress(\n    data={\"df\": df},\n    rvar=\"gave\",\n    evar=\"treatment\"\n)\nreg.summary()\n\n\n\n\nRegression output\n\n\nThe results above show that the treatment group had a statistically significantly higher probability of making a donation compared to the control group.\n\nThe bar chart illustrates a clear increase in donation rate for the treatment group.\nA two-sample t-test confirms this difference is statistically significant (p = 0.0013).\nA linear regression further supports this finding, with the treatment coefficient estimated at 0.004 (p = 0.002).\n\nThese results suggest that matched donation offers increased individuals’ likelihood of contributing. In behavioral terms, this implies people respond positively to incentives that enhance the perceived value of their contributions—highlighting the effectiveness of “matching” as a behavioral nudge.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nT-test Comparisons\n\nfrom scipy.stats import ttest_ind\n\ngave_1to1 = df[df[\"ratio2\"] == 0][df[\"ratio3\"] == 0][\"gave\"]\ngave_2to1 = df[df[\"ratio2\"] == 1][\"gave\"]\ngave_3to1 = df[df[\"ratio3\"] == 1][\"gave\"]\n\n# t-test: 1:1 vs 2:1\ntstat_12, pval_12 = ttest_ind(gave_1to1, gave_2to1, equal_var=False)\n\n# t-test: 2:1 vs 3:1\ntstat_23, pval_23 = ttest_ind(gave_2to1, gave_3to1, equal_var=False)\n\nprint(f\"1:1 vs 2:1 -&gt; t = {tstat_12:.3f}, p = {pval_12:.4f}\")\nprint(f\"2:1 vs 3:1 -&gt; t = {tstat_23:.3f}, p = {pval_23:.4f}\")\n\n1:1 vs 2:1 -&gt; t = -2.220, p = 0.0265\n2:1 vs 3:1 -&gt; t = -0.050, p = 0.9600\n\n\n/tmp/ipykernel_215826/3218956970.py:3: UserWarning:\n\nBoolean Series key will be reindexed to match DataFrame index.\n\n\n\n\nimport pyrsm as rsm\n\nreg = rsm.model.regress(\n    data={\"df\": df},\n    rvar=\"gave\",\n    evar=[\"ratio2\", \"ratio3\"]\n)\n\nreg.summary()\n\nLinear regression (OLS)\nData                 : df\nResponse variable    : gave\nExplanatory variables: ratio2, ratio3\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.019      0.001   22.306  &lt; .001  ***\nratio2           0.004      0.002    2.269   0.023    *\nratio3           0.004      0.002    2.332    0.02    *\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 4.117 df(2, 50080), p.value 0.016\nNr obs: 50,083\n\n\n\n\n\nInterpretation\nThe goal of this analysis was to evaluate whether increasing the generosity of the match (e.g., from 1:1 to 2:1 or 3:1) leads to higher donation rates.\nThe t-test results show that: - Moving from a 1:1 match to a 2:1 match results in a statistically significant increase in donations (p = 0.0265). - However, moving from a 2:1 to a 3:1 match shows no significant difference (p = 0.96), suggesting diminishing returns.\nThe linear regression results confirm this pattern: - Both ratio2 and ratio3 are associated with a significant increase in donation likelihood relative to the 1:1 baseline. - However, the effect sizes are identical (0.004), which suggests that the existence of a match matters more than its magnitude.\nFrom a behavioral perspective, this implies that: - Donors respond positively to the idea of their contribution being matched—it feels more “impactful.” - But increasing the match beyond a certain point does not make giving feel significantly better, nor does it increase motivation.\nIn short, the presence of a match drives behavior, not the size of the multiplier.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nimport pyrsm as rsm\n\nreg = rsm.model.regress(\n    data={\"df\": df},\n    rvar=\"amount\",\n    evar=\"treatment\"\n)\nreg.summary()\n\nLinear regression (OLS)\nData                 : df\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.813      0.067   12.063  &lt; .001  ***\ntreatment        0.154      0.083    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.461 df(1, 50081), p.value 0.063\nNr obs: 50,083\n\n\n\ndonated_df = df[df[\"gave\"] == 1]\n\nreg2 = rsm.model.regress(\n    data={\"df\": donated_df},\n    rvar=\"amount\",\n    evar=\"treatment\"\n)\nreg2.summary()\n\nLinear regression (OLS)\nData                 : df\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       45.540      2.423   18.792  &lt; .001  ***\ntreatment       -1.668      2.872   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.001\nF-statistic: 0.337 df(1, 1032), p.value 0.561\nNr obs: 1,034\n\n\n\nimport matplotlib.pyplot as plt\n\ndonated = df[df[\"gave\"] == 1]\ncontrol = donated[donated[\"treatment\"] == 0][\"amount\"]\ntreatment = donated[donated[\"treatment\"] == 1][\"amount\"]\n\nplt.hist(control, bins=30, alpha=0.6, label=\"Control\", color=\"gray\", edgecolor=\"black\")\nplt.axvline(control.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean Control: ${control.mean():.2f}\")\n\nplt.hist(treatment, bins=30, alpha=0.6, label=\"Treatment\", color=\"steelblue\", edgecolor=\"black\")\nplt.axvline(treatment.mean(), color=\"blue\", linestyle=\"--\", label=f\"Mean Treatment: ${treatment.mean():.2f}\")\n\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of Donation Amounts (Given Donation)\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nWe assess whether the treatment affects the size of donations, not just the likelihood of giving.\n\nIn the full sample, a regression of amount ~ treatment shows no significant effect of the treatment on donation amount (including zeros).\nHowever, when limiting to individuals who actually donated, the conditional regression shows whether treatment increases the average size of the donation.\nFrom the histogram, we see that the distributions of donation amounts are relatively similar between groups, but the average donation is slightly higher in the treatment group.\n\nThese results suggest that while matched donations increase the likelihood of donating, they do not substantially alter the amount people choose to give once they’ve decided to donate. This implies that matching functions primarily as a participation nudge rather than a motivation to give more."
  },
  {
    "objectID": "project/hw1/hw1_questions.html#simulation-experiment",
    "href": "project/hw1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\np_control = 0.018\np_treatment = 0.022\nn = 10000\n\ncontrol = np.random.binomial(1, p_control, n)\ntreatment = np.random.binomial(1, p_treatment, n)\n\ndiffs = treatment - control\n\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)\n\nplt.figure()\nplt.plot(cumulative_avg, label=\"Cumulative Avg. of Differences\")\nplt.axhline(0.004, color=\"red\", linestyle=\"--\", label=\"True Treatment Effect (0.004)\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Average Treatment Effect\")\nplt.title(\"Law of Large Numbers in Action\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThis simulation visually demonstrates the Law of Large Numbers in the context of charitable donation data.\n\nInitially, the sample average of the difference between treatment and control is quite noisy and volatile.\nAs the number of observations increases, the cumulative average converges to the true treatment effect (0.004).\nThis supports the idea that with a large enough sample, sample-based statistics become reliable estimates of population parameters.\n\nThis experiment also reinforces why larger sample sizes are crucial for statistical inference, and why the t-statistic is more trustworthy when n is large.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_sim = 1000\n\nfig, axes = plt.subplots(2, 2, figsize=(10, 6))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n\n    for _ in range(n_sim):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        diffs.append(diff)\n\n    axes[i].hist(diffs, bins=30, color=\"skyblue\", edgecolor=\"black\", density=True)\n    axes[i].axvline(np.mean(diffs), color=\"red\", linestyle=\"--\", label=f\"Mean: {np.mean(diffs):.4f}\")\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Sample Mean Difference\")\n    axes[i].set_ylabel(\"Density\")\n    axes[i].legend()\n\nplt.suptitle(\"CLT Simulation: Distribution of Sample Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThis simulation demonstrates the Central Limit Theorem (CLT) by showing how the distribution of average treatment effects evolves with increasing sample size.\nEach histogram represents 1,000 simulations of the difference in means between treatment and control groups, at different sample sizes.\n\nAt n = 50, the distribution is jagged and skewed—far from normal.\nAs sample size increases (to 200, 500, and 1000), the distribution becomes smoother and more bell-shaped, eventually closely approximating a normal distribution.\n\nThis illustrates the CLT in action: regardless of the underlying distribution (Bernoulli here), the distribution of the sample mean tends toward normality as n increases. This justifies using t-tests and linear models for inference in randomized experiments like this one.\n\n\nInterpretation\nThis simulation illustrates the Central Limit Theorem (CLT) using differences in sample means between treatment and control groups.\nEach panel shows the distribution of 1,000 simulated average treatment effects (ATEs) at different sample sizes:\n\nAt n = 50, the distribution is irregular and spiky, showing high variability.\nAt n = 200, the distribution begins to smooth out, but is still visibly skewed.\nAt n = 500, it begins to resemble a normal distribution.\nAt n = 1000, the distribution is approximately bell-shaped and symmetric.\n\nThis visual progression confirms the CLT:\n&gt; As sample size increases, the distribution of the sample mean approaches a normal distribution, regardless of the underlying population distribution (Bernoulli in this case).\nThis is why classical statistical tools like t-tests are valid for large enough samples—even when the data is binary or skewed at the individual level."
  },
  {
    "objectID": "project/hw1/work flow.html",
    "href": "project/hw1/work flow.html",
    "title": "Home",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_stata('karlan_list_2007.dta')\n\nprint(df.head())\n\n   treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n0          0        1  Control       0       0   Control       0       0   \n1          0        1  Control       0       0   Control       0       0   \n2          1        0        1       0       0  $100,000       0       0   \n3          1        0        1       0       0  Unstated       0       0   \n4          1        0        1       0       0   $50,000       0       1   \n\n   size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n\n   ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n0       2.10          28517.0  0.499807      0.324528            1.0  \n1        NaN              NaN       NaN           NaN            NaN  \n2       2.48          51175.0  0.721941      0.192668            1.0  \n3       2.65          79269.0  0.920431      0.412142            1.0  \n4       1.85          40908.0  0.416072      0.439965            1.0  \n\n[5 rows x 51 columns]"
  }
]