[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ethan An",
    "section": "",
    "text": "current\nOperation | Eastwest Bank\nMaster of business analytics | Rady school of management"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Ethan’s project",
    "section": "",
    "text": "Homework 2: Poisson Regression Examples\n\n\n\n\n\n\nEthan An\n\n\nMay 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 1: A Replication of Karlan and List (2007)\n\n\n\n\n\n\nEthan An\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Resume",
    "section": "",
    "text": "Last update 2024_06_01\nDownload PDF file."
  },
  {
    "objectID": "project/hw1/hw1_questions.html",
    "href": "project/hw1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nTo better understand how pricing mechanisms affect charitable giving, Karlan and List implemented a large-scale natural field experiment involving over 50,000 prior donors to a politically active nonprofit organization. Participants were randomly assigned to one of several groups:\n\nA control group, receiving a standard fundraising letter with no mention of a match.\nOne or more treatment groups, receiving letters offering a matching grant of varying ratios—$1:$1, $2:$1, or $3:$1.\nEach treatment also varied the maximum matching amount (e.g., $25,000 or $100,000), and suggested donation levels (based on prior donations).\n\nThis experimental design allowed the researchers to isolate the causal effect of matching offers—both their presence and their generosity—on the likelihood of donating and the amount donated. It also enabled an exploration of how political context might moderate these effects.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "project/hw1/hw1_questions.html#introduction",
    "href": "project/hw1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nTo better understand how pricing mechanisms affect charitable giving, Karlan and List implemented a large-scale natural field experiment involving over 50,000 prior donors to a politically active nonprofit organization. Participants were randomly assigned to one of several groups:\n\nA control group, receiving a standard fundraising letter with no mention of a match.\nOne or more treatment groups, receiving letters offering a matching grant of varying ratios—$1:$1, $2:$1, or $3:$1.\nEach treatment also varied the maximum matching amount (e.g., $25,000 or $100,000), and suggested donation levels (based on prior donations).\n\nThis experimental design allowed the researchers to isolate the causal effect of matching offers—both their presence and their generosity—on the likelihood of donating and the amount donated. It also enabled an exploration of how political context might moderate these effects.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "project/hw1/hw1_questions.html#data",
    "href": "project/hw1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\nWe load the dataset provided by Karlan and List (2007), which contains responses from over 50,000 previous donors who were randomly assigned to receive different versions of a fundraising letter. The dataset includes treatment assignments (e.g., control vs. matching grant groups), donation outcomes, and demographic/political context data.\nThe data has 50,083 observations and 51 variables. Some of the key variables include:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nfrom scipy import stats\nimport pandas as pd\n\ntreated = df[df[\"treatment\"] == 1]\ncontrol = df[df[\"control\"] == 1]\n\nvars_to_test = [\"years\", \"freq\", \"mrm2\", \"female\", \"couple\"]\nbalance_table = []\n\nfor var in vars_to_test:\n    t_mean = treated[var].mean()\n    c_mean = control[var].mean()\n    t_stat, p_val = stats.ttest_ind(treated[var].dropna(), control[var].dropna(), equal_var=False)\n    balance_table.append((var, round(c_mean, 2), round(t_mean, 2), round(p_val, 4)))\n\npd.DataFrame(balance_table, columns=[\"Variable\", \"Control Mean\", \"Treatment Mean\", \"p-value\"])\n\n\n\n\n\n\n\nVariable\nControl Mean\nTreatment Mean\np-value\n\n\n\n\n0\nyears\n6.14\n6.08\n0.2753\n\n\n1\nfreq\n8.05\n8.04\n0.9117\n\n\n2\nmrm2\n13.00\n13.01\n0.9049\n\n\n3\nfemale\n0.28\n0.28\n0.0795\n\n\n4\ncouple\n0.09\n0.09\n0.5604\n\n\n\n\n\nBased on the p-values, we observe that none of the variables differ significantly between the two groups at the 5% level. This supports the notion that random assignment was successful and that the treatment and control groups are statistically balanced at baseline.\nTo confirm this, we also fit a simple linear regression model: ### Regression: Effect of Treatment on Prior Giving Behavior\nWe use a linear regression to test whether prior donation behavior (mrm2) differs across treatment groups. This serves as a balance check for the experimental design.\n\nimport pyrsm as rsm\n\nreg = rsm.model.regress(\n    data={\"df\": df},\n    rvar=\"mrm2\",\n    evar=\"treatment\"\n)\n\nreg.summary()\n\nThe regression output is summarized in the following screenshot:\n\n\n\nRegression output\n\n\nThe treatment coefficient is small (0.014) and statistically insignificant (p = 0.905), indicating that the treatment and control groups were well balanced in terms of prior maximum donations.\nThis supports the validity of the random assignment mechanism."
  },
  {
    "objectID": "project/hw1/hw1_questions.html#experimental-results",
    "href": "project/hw1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\ndonation_rate = df.groupby(\"treatment\")[\"gave\"].mean().rename({0: \"Control\", 1: \"Treatment\"})\n\ndonation_rate.plot(kind=\"bar\", color=[\"gray\", \"steelblue\"], edgecolor=\"black\")\nplt.title(\"Donation Rate by Treatment Group\")\nplt.ylabel(\"Proportion Donated\")\nplt.ylim(0, 0.03)\nplt.xticks(rotation=0)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\n\ntreated = df[df[\"treatment\"] == 1][\"gave\"]\ncontrol = df[df[\"treatment\"] == 0][\"gave\"]\n\nt_stat, p_val = ttest_ind(treated, control, equal_var=False)\nprint(f\"T-statistic = {t_stat:.3f}, p-value = {p_val:.4f}\")\n\nT-statistic = 3.209, p-value = 0.0013\n\n\n\nimport pyrsm as rsm\n\nreg = rsm.model.regress(\n    data={\"df\": df},\n    rvar=\"gave\",\n    evar=\"treatment\"\n)\nreg.summary()\n\n\n\n\nRegression output\n\n\nThe results above show that the treatment group had a statistically significantly higher probability of making a donation compared to the control group.\n\nThe bar chart illustrates a clear increase in donation rate for the treatment group.\nA two-sample t-test confirms this difference is statistically significant (p = 0.0013).\nA linear regression further supports this finding, with the treatment coefficient estimated at 0.004 (p = 0.002).\n\nThese results suggest that matched donation offers increased individuals’ likelihood of contributing. In behavioral terms, this implies people respond positively to incentives that enhance the perceived value of their contributions—highlighting the effectiveness of “matching” as a behavioral nudge.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nT-test Comparisons\n\nfrom scipy.stats import ttest_ind\n\ngave_1to1 = df[df[\"ratio2\"] == 0][df[\"ratio3\"] == 0][\"gave\"]\ngave_2to1 = df[df[\"ratio2\"] == 1][\"gave\"]\ngave_3to1 = df[df[\"ratio3\"] == 1][\"gave\"]\n\n# t-test: 1:1 vs 2:1\ntstat_12, pval_12 = ttest_ind(gave_1to1, gave_2to1, equal_var=False)\n\n# t-test: 2:1 vs 3:1\ntstat_23, pval_23 = ttest_ind(gave_2to1, gave_3to1, equal_var=False)\n\nprint(f\"1:1 vs 2:1 -&gt; t = {tstat_12:.3f}, p = {pval_12:.4f}\")\nprint(f\"2:1 vs 3:1 -&gt; t = {tstat_23:.3f}, p = {pval_23:.4f}\")\n\n1:1 vs 2:1 -&gt; t = -2.220, p = 0.0265\n2:1 vs 3:1 -&gt; t = -0.050, p = 0.9600\n\n\n/tmp/ipykernel_3432/3218956970.py:3: UserWarning:\n\nBoolean Series key will be reindexed to match DataFrame index.\n\n\n\n\nimport pyrsm as rsm\n\nreg = rsm.model.regress(\n    data={\"df\": df},\n    rvar=\"gave\",\n    evar=[\"ratio2\", \"ratio3\"]\n)\n\nreg.summary()\n\nLinear regression (OLS)\nData                 : df\nResponse variable    : gave\nExplanatory variables: ratio2, ratio3\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.019      0.001   22.306  &lt; .001  ***\nratio2           0.004      0.002    2.269   0.023    *\nratio3           0.004      0.002    2.332    0.02    *\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 4.117 df(2, 50080), p.value 0.016\nNr obs: 50,083\n\n\n\n\n\nInterpretation\nThe goal of this analysis was to evaluate whether increasing the generosity of the match (e.g., from 1:1 to 2:1 or 3:1) leads to higher donation rates.\nThe t-test results show that: - Moving from a 1:1 match to a 2:1 match results in a statistically significant increase in donations (p = 0.0265). - However, moving from a 2:1 to a 3:1 match shows no significant difference (p = 0.96), suggesting diminishing returns.\nThe linear regression results confirm this pattern: - Both ratio2 and ratio3 are associated with a significant increase in donation likelihood relative to the 1:1 baseline. - However, the effect sizes are identical (0.004), which suggests that the existence of a match matters more than its magnitude.\nFrom a behavioral perspective, this implies that: - Donors respond positively to the idea of their contribution being matched—it feels more “impactful.” - But increasing the match beyond a certain point does not make giving feel significantly better, nor does it increase motivation.\nIn short, the presence of a match drives behavior, not the size of the multiplier.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nimport pyrsm as rsm\n\nreg = rsm.model.regress(\n    data={\"df\": df},\n    rvar=\"amount\",\n    evar=\"treatment\"\n)\nreg.summary()\n\nLinear regression (OLS)\nData                 : df\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.813      0.067   12.063  &lt; .001  ***\ntreatment        0.154      0.083    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.461 df(1, 50081), p.value 0.063\nNr obs: 50,083\n\n\n\ndonated_df = df[df[\"gave\"] == 1]\n\nreg2 = rsm.model.regress(\n    data={\"df\": donated_df},\n    rvar=\"amount\",\n    evar=\"treatment\"\n)\nreg2.summary()\n\nLinear regression (OLS)\nData                 : df\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       45.540      2.423   18.792  &lt; .001  ***\ntreatment       -1.668      2.872   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.001\nF-statistic: 0.337 df(1, 1032), p.value 0.561\nNr obs: 1,034\n\n\n\nimport matplotlib.pyplot as plt\n\ndonated = df[df[\"gave\"] == 1]\ncontrol = donated[donated[\"treatment\"] == 0][\"amount\"]\ntreatment = donated[donated[\"treatment\"] == 1][\"amount\"]\n\nplt.hist(control, bins=30, alpha=0.6, label=\"Control\", color=\"gray\", edgecolor=\"black\")\nplt.axvline(control.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean Control: ${control.mean():.2f}\")\n\nplt.hist(treatment, bins=30, alpha=0.6, label=\"Treatment\", color=\"steelblue\", edgecolor=\"black\")\nplt.axvline(treatment.mean(), color=\"blue\", linestyle=\"--\", label=f\"Mean Treatment: ${treatment.mean():.2f}\")\n\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of Donation Amounts (Given Donation)\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nWe assess whether the treatment affects the size of donations, not just the likelihood of giving.\n\nIn the full sample, a regression of amount ~ treatment shows no significant effect of the treatment on donation amount (including zeros).\nHowever, when limiting to individuals who actually donated, the conditional regression shows whether treatment increases the average size of the donation.\nFrom the histogram, we see that the distributions of donation amounts are relatively similar between groups, but the average donation is slightly higher in the treatment group.\n\nThese results suggest that while matched donations increase the likelihood of donating, they do not substantially alter the amount people choose to give once they’ve decided to donate. This implies that matching functions primarily as a participation nudge rather than a motivation to give more."
  },
  {
    "objectID": "project/hw1/hw1_questions.html#simulation-experiment",
    "href": "project/hw1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\np_control = 0.018\np_treatment = 0.022\nn = 10000\n\ncontrol = np.random.binomial(1, p_control, n)\ntreatment = np.random.binomial(1, p_treatment, n)\n\ndiffs = treatment - control\n\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)\n\nplt.figure()\nplt.plot(cumulative_avg, label=\"Cumulative Avg. of Differences\")\nplt.axhline(0.004, color=\"red\", linestyle=\"--\", label=\"True Treatment Effect (0.004)\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Average Treatment Effect\")\nplt.title(\"Law of Large Numbers in Action\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThis simulation visually demonstrates the Law of Large Numbers in the context of charitable donation data.\n\nInitially, the sample average of the difference between treatment and control is quite noisy and volatile.\nAs the number of observations increases, the cumulative average converges to the true treatment effect (0.004).\nThis supports the idea that with a large enough sample, sample-based statistics become reliable estimates of population parameters.\n\nThis experiment also reinforces why larger sample sizes are crucial for statistical inference, and why the t-statistic is more trustworthy when n is large.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_sim = 1000\n\nfig, axes = plt.subplots(2, 2, figsize=(10, 6))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n\n    for _ in range(n_sim):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        diffs.append(diff)\n\n    axes[i].hist(diffs, bins=30, color=\"skyblue\", edgecolor=\"black\", density=True)\n    axes[i].axvline(np.mean(diffs), color=\"red\", linestyle=\"--\", label=f\"Mean: {np.mean(diffs):.4f}\")\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Sample Mean Difference\")\n    axes[i].set_ylabel(\"Density\")\n    axes[i].legend()\n\nplt.suptitle(\"CLT Simulation: Distribution of Sample Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThis simulation demonstrates the Central Limit Theorem (CLT) by showing how the distribution of average treatment effects evolves with increasing sample size.\nEach histogram represents 1,000 simulations of the difference in means between treatment and control groups, at different sample sizes.\n\nAt n = 50, the distribution is jagged and skewed—far from normal.\nAs sample size increases (to 200, 500, and 1000), the distribution becomes smoother and more bell-shaped, eventually closely approximating a normal distribution.\n\nThis illustrates the CLT in action: regardless of the underlying distribution (Bernoulli here), the distribution of the sample mean tends toward normality as n increases. This justifies using t-tests and linear models for inference in randomized experiments like this one.\n\n\nInterpretation\nThis simulation illustrates the Central Limit Theorem (CLT) using differences in sample means between treatment and control groups.\nEach panel shows the distribution of 1,000 simulated average treatment effects (ATEs) at different sample sizes:\n\nAt n = 50, the distribution is irregular and spiky, showing high variability.\nAt n = 200, the distribution begins to smooth out, but is still visibly skewed.\nAt n = 500, it begins to resemble a normal distribution.\nAt n = 1000, the distribution is approximately bell-shaped and symmetric.\n\nThis visual progression confirms the CLT:\n&gt; As sample size increases, the distribution of the sample mean approaches a normal distribution, regardless of the underlying population distribution (Bernoulli in this case).\nThis is why classical statistical tools like t-tests are valid for large enough samples—even when the data is binary or skewed at the individual level."
  },
  {
    "objectID": "project/hw1/work flow.html",
    "href": "project/hw1/work flow.html",
    "title": "Home",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_stata('karlan_list_2007.dta')\n\ndf_info = df.info()\ndf_head = df.head()\n\ndf_info, df_head\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n(None,\n    treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n 0          0        1  Control       0       0   Control       0       0   \n 1          0        1  Control       0       0   Control       0       0   \n 2          1        0        1       0       0  $100,000       0       0   \n 3          1        0        1       0       0  Unstated       0       0   \n 4          1        0        1       0       0   $50,000       0       1   \n \n    size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n 0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n 1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n 2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n 3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n 4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n \n    ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n 0       2.10          28517.0  0.499807      0.324528            1.0  \n 1        NaN              NaN       NaN           NaN            NaN  \n 2       2.48          51175.0  0.721941      0.192668            1.0  \n 3       2.65          79269.0  0.920431      0.412142            1.0  \n 4       1.85          40908.0  0.416072      0.439965            1.0  \n \n [5 rows x 51 columns])"
  },
  {
    "objectID": "project/hw2/hw2_questions.html",
    "href": "project/hw2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv(\"blueprinty.csv\")\n\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", bins=30, multiple=\"dodge\", palette=\"Set2\")\nplt.title(\"Distribution of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Count\")\nplt.legend(title=\"Is Customer\", labels=[\"Non-Customer\", \"Customer\"])\nplt.show()\n\nmeans = df.groupby(\"iscustomer\")[\"patents\"].mean()\nprint(\"Mean number of patents:\")\nprint(\"  Non-Customers:\", round(means[0], 2))\nprint(\"  Customers:\", round(means[1], 2))\n Mean number of patents: Non-Customers: 3.47 Customers: 4.13\nWe observe that Blueprinty customers tend to have more patents on average than non-customers. The distribution of patent counts is right-skewed for both groups, but customers are more concentrated in the higher patent range (e.g., 5 or more patents).\n\n\n\n\nMean patents (Customers): 4.13\n\nMean patents (Non-Customers): 3.47\n\nThis suggests a potential positive association between using Blueprinty’s software and patenting success. However, we cannot infer causality from this descriptive comparison alone.\nIt is possible that firms more active in patenting are also more likely to adopt Blueprinty’s software. Therefore, it is important to control for potential confounding variables such as firm age and regional location in the regression analysis that follows.\nregion_table = df.groupby(\"iscustomer\")[\"region\"].value_counts(normalize=True).unstack().round(3)\nregion_table \n\n\n\n\n\n\nregion\nMidwest\nNortheast\nNorthwest\nSouth\nSouthwest\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n0\n0.184\n0.268\n0.155\n0.153\n0.240\n\n\n1\n0.077\n0.682\n0.060\n0.073\n0.108\n\n\n\n\n\nage_table = df.groupby(\"iscustomer\")[\"age\"].mean().round(2)\nage_table\niscustomer\n0    26.1\n1    26.9\nName: age, dtype: float64\nWe observe notable differences in region distribution and firm age between Blueprinty customers and non-customers:\n\nRegion:\n\nAmong customers, ~68% are from the Northeast, with fewer in the Southwest (~11%), Midwest (~8%), South (~7%), and Northwest (~6%).\nAmong non-customers, the Northeast accounts for only ~27%, with larger proportions in the Southwest (~24%), Midwest (~18%), South (~15%), and Northwest (~15%).\n\nAverage Firm Age:\n\nCustomers: 26.90 years\n\nNon-customers: 26.10 years\n\n\nThese patterns suggest that customer status is not random and must be accounted for in any causal inference. We’ll include both region and age as covariates in our regression model.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nFor a sample of ( n ) independent observations, the likelihood function is:\n\\[S\nL(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nTaking the log of the likelihood (log-likelihood), we get:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nfrom scipy.special import gammaln  # gammaln(y+1) = log(y!)\n\ndef poisson_loglikelihood(lamb, Y):\n    if lamb &lt;= 0:\n        return -1e6\n    loglik = np.sum(-lamb + Y * np.log(lamb) - gammaln(Y + 1))\n    return loglik\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.special import gammaln\n\ndef poisson_loglikelihood(lamb, Y):\n    if lamb &lt;= 0:\n        return -1e6\n    return np.sum(-lamb + Y * np.log(lamb) - gammaln(Y + 1))\n\nY = df[\"patents\"].values\n\nlambda_grid = np.linspace(0.1, 10, 200)\n\nloglik_vals = [poisson_loglikelihood(l, Y) for l in lambda_grid]\n\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_grid, loglik_vals, label=\"Log-Likelihood\")\nplt.xlabel(r\"$\\lambda$\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Log-Likelihood Curve for Poisson Model\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\nfrom scipy.optimize import minimize_scalar\n\nY = df[\"patents\"].values\n\nresult = minimize_scalar(\n    lambda l: -poisson_loglikelihood(l, Y),\n    bounds=(0.1, 10), \n    method='bounded'\n)\n\nprint(\"Estimated λ (MLE):\", round(result.x, 4))\nprint(\"Maximum Log-Likelihood:\", round(-result.fun, 2))\nEstimated λ (MLE): 3.6847 Maximum Log-Likelihood: -3367.68\n\n\n\nUsing our hand-coded Poisson log-likelihood function and the scipy.optimize.minimize_scalar() method,\nwe estimated the average number of patents per firm (λ) that best fits the data.\n\nEstimated λ (MLE): 3.6847\n\nMaximum Log-Likelihood: -3367.68\n\nThis estimate maximizes the log-likelihood of observing the actual distribution of patents across firms,\nassuming a Poisson model. This λ will serve as the baseline for further regression modeling.\nWe now derive the maximum likelihood estimator (MLE) for λ analytically.\nRecall the log-likelihood function for the Poisson distribution:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative with respect to λ:\n\\[\n\\frac{d\\ell}{d\\lambda} = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n= -n + \\frac{1}{\\lambda} \\sum_{i=1}^{n} Y_i\n\\]\nSet the derivative equal to 0 and solve:\n\\[\n-n + \\frac{\\sum Y_i}{\\lambda} = 0 \\quad \\Rightarrow \\quad \\lambda = \\frac{1}{n} \\sum Y_i = \\bar{Y}\n\\]\nThus, the MLE for λ is simply the sample mean of the observed values:\n\\[\n\\hat{\\lambda}_{MLE} = \\bar{Y}\n\\]\nThis result makes intuitive sense: in a Poisson distribution, the mean equals the rate parameter (λ),\nso the best estimate of λ is just the average observed number of patents.\nfrom scipy.optimize import minimize_scalar\n\nY = df[\"patents\"].values\n\nresult = minimize_scalar(\n    lambda l: -poisson_loglikelihood(l, Y),\n    bounds=(0.1, 10),\n    method='bounded'\n)\n\nprint(\"Estimated λ (MLE):\", round(result.x, 4))\nprint(\"Maximum Log-Likelihood:\", round(-result.fun, 2))\nEstimated λ (MLE): 3.6847 Maximum Log-Likelihood: -3367.68\nWe computed the MLE for λ by numerically optimizing our hand-coded log-likelihood function using\nscipy.optimize.minimize_scalar() in Python. The optimizer returned the following result:\n\nEstimated λ (MLE): 3.6847\n\nMaximum Log-Likelihood: -3367.68\n\nThis aligns with the theoretical result that the MLE of λ for a Poisson distribution is the sample mean.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\nX = df[[\"age\"]].copy()\nX[\"age_sq\"] = df[\"age\"] ** 2\nX = pd.get_dummies(X.join(df[\"region\"]), drop_first=True)\nX[\"iscustomer\"] = df[\"iscustomer\"]\nX = sm.add_constant(X)\n\nX_mat = X.to_numpy(dtype=float)\nY = df[\"patents\"].to_numpy(dtype=int)\n\ndef poisson_loglikelihood(beta, X, Y):\n    beta = np.asarray(beta)\n    eta = X @ beta\n    eta = np.clip(eta, -20, 20)             \n    lambda_i = np.exp(eta)\n    loglik = np.sum(-lambda_i + Y * np.log(lambda_i) - gammaln(Y + 1))\n    return -loglik\n\ninit_beta = np.zeros(X_mat.shape[1])\n\nresult = minimize(\n    fun=poisson_loglikelihood,\n    x0=init_beta,\n    args=(X_mat, Y),\n    method=\"BFGS\",\n    options={\"disp\": True}\n)\n\nbeta_hat = result.x\nhessian_inv = result.hess_inv \nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\ncoef_table = pd.DataFrame({\n    \"Variable\": X.columns,\n    \"Estimate\": np.round(beta_hat, 4),\n    \"Std. Error\": np.round(standard_errors, 4)\n})\n\nprint(coef_table)\n     Current function value: 3258.072164\n     Iterations: 14\n     Function evaluations: 759\n     Gradient evaluations: 83\n       Variable  Estimate  Std. Error\n0 const -0.5100 0.1930 1 age 0.1487 0.0145 2 age_sq -0.0030 0.0003 3 region_Northeast 0.0292 0.0468 4 region_Northwest -0.0176 0.0572 5 region_South 0.0566 0.0562 6 region_Southwest 0.0506 0.0496 7 iscustomer 0.2076 0.0329\n/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py:708: OptimizeWarning:\n\nDesired error not necessarily achieved due to precision loss.\n\n\n\n\nWe estimated a Poisson regression model using maximum likelihood, where the log of the expected number of patents per firm is modeled as a linear function of firm characteristics.\nThe results indicate that:\n\nAge is positively associated with patent counts, but with a diminishing return (age squared is negative and significant).\nBlueprinty customers file significantly more patents, on average. The coefficient on iscustomer is +0.2076, with a standard error of 0.0329, indicating a statistically significant effect.\nRegion effects are small and mostly not statistically significant relative to the omitted base category.\n\nExponentiating the iscustomer coefficient gives:\n\\[\n\\exp(0.2076) \\approx 1.23\n\\]\nThis suggests that, holding other variables constant, Blueprinty customers are expected to have ~23% more patents than non-customers.\n\nimport statsmodels.api as sm\n\nX_fixed = X.astype(\"float\")\n\n\nglm_poisson = sm.GLM(df[\"patents\"], X_fixed, family=sm.families.Poisson())\nglm_results = glm_poisson.fit()\nprint(glm_results.summary())\n\n\n\n\nThe following shows the fitted Poisson regression results using Python’s built-in GLM() function:\n\n\n\n\nThe Poisson regression model estimates the expected number of patents awarded to a firm as a function of its characteristics. The key findings are:\n\nAge has a positive and statistically significant coefficient (0.1486), meaning that older firms tend to file more patents.\nHowever, the negative coefficient on age squared (-0.0030) indicates diminishing returns — the relationship is concave.\nRegion indicators are not statistically significant at the 5% level, suggesting little difference in patenting behavior across regions once other factors are controlled for.\nMost importantly, the coefficient on iscustomer is 0.2076 and highly significant (p &lt; 0.001).\nThis implies that, holding other factors constant, Blueprinty customers are associated with higher expected patent counts.\nSpecifically, exponentiating the coefficient gives:\n\\[\n\\exp(0.2076) \\approx 1.23\n\\]\nMeaning Blueprinty customers are expected to file approximately 23% more patents than non-customers, all else equal.\n\nThis result supports the claim that using Blueprinty’s software is associated with greater patenting activity.\nX_0 = X.copy()\nX_0[\"iscustomer\"] = 0\nX_0 = X_0.astype(float) \n\nX_1 = X.copy()\nX_1[\"iscustomer\"] = 1\nX_1 = X_1.astype(float)\n\ny_pred_0 = glm_results.predict(X_0)\ny_pred_1 = glm_results.predict(X_1)\n\navg_diff = (y_pred_1 - y_pred_0).mean()\nprint(\"Average predicted patent increase due to Blueprinty:\", round(avg_diff, 4))\nAverage predicted patent increase due to Blueprinty: 0.7928\n\n\n\nTo better understand the impact of Blueprinty software, we simulated a counterfactual scenario:\n\nWe predicted the number of patents for each firm assuming they do not use Blueprinty (set iscustomer = 0)\nThen we predicted the number assuming all firms use Blueprinty (iscustomer = 1)\n\nBy taking the difference in predicted patent counts for each firm and averaging, we estimate the average treatment effect.\nResult:\nIf all firms were Blueprinty customers, the average predicted number of patents would increase by 0.7928.\nThis suggests that Blueprinty’s software is associated with a meaningful increase in patent productivity, even after controlling for firm age and region."
  },
  {
    "objectID": "project/hw2/hw2_questions.html#blueprinty-case-study",
    "href": "project/hw2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv(\"blueprinty.csv\")\n\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", bins=30, multiple=\"dodge\", palette=\"Set2\")\nplt.title(\"Distribution of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Count\")\nplt.legend(title=\"Is Customer\", labels=[\"Non-Customer\", \"Customer\"])\nplt.show()\n\nmeans = df.groupby(\"iscustomer\")[\"patents\"].mean()\nprint(\"Mean number of patents:\")\nprint(\"  Non-Customers:\", round(means[0], 2))\nprint(\"  Customers:\", round(means[1], 2))\n Mean number of patents: Non-Customers: 3.47 Customers: 4.13\nWe observe that Blueprinty customers tend to have more patents on average than non-customers. The distribution of patent counts is right-skewed for both groups, but customers are more concentrated in the higher patent range (e.g., 5 or more patents).\n\n\n\n\nMean patents (Customers): 4.13\n\nMean patents (Non-Customers): 3.47\n\nThis suggests a potential positive association between using Blueprinty’s software and patenting success. However, we cannot infer causality from this descriptive comparison alone.\nIt is possible that firms more active in patenting are also more likely to adopt Blueprinty’s software. Therefore, it is important to control for potential confounding variables such as firm age and regional location in the regression analysis that follows.\nregion_table = df.groupby(\"iscustomer\")[\"region\"].value_counts(normalize=True).unstack().round(3)\nregion_table \n\n\n\n\n\n\nregion\nMidwest\nNortheast\nNorthwest\nSouth\nSouthwest\n\n\niscustomer\n\n\n\n\n\n\n\n\n\n0\n0.184\n0.268\n0.155\n0.153\n0.240\n\n\n1\n0.077\n0.682\n0.060\n0.073\n0.108\n\n\n\n\n\nage_table = df.groupby(\"iscustomer\")[\"age\"].mean().round(2)\nage_table\niscustomer\n0    26.1\n1    26.9\nName: age, dtype: float64\nWe observe notable differences in region distribution and firm age between Blueprinty customers and non-customers:\n\nRegion:\n\nAmong customers, ~68% are from the Northeast, with fewer in the Southwest (~11%), Midwest (~8%), South (~7%), and Northwest (~6%).\nAmong non-customers, the Northeast accounts for only ~27%, with larger proportions in the Southwest (~24%), Midwest (~18%), South (~15%), and Northwest (~15%).\n\nAverage Firm Age:\n\nCustomers: 26.90 years\n\nNon-customers: 26.10 years\n\n\nThese patterns suggest that customer status is not random and must be accounted for in any causal inference. We’ll include both region and age as covariates in our regression model.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nFor a sample of ( n ) independent observations, the likelihood function is:\n\\[S\nL(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nTaking the log of the likelihood (log-likelihood), we get:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nfrom scipy.special import gammaln  # gammaln(y+1) = log(y!)\n\ndef poisson_loglikelihood(lamb, Y):\n    if lamb &lt;= 0:\n        return -1e6\n    loglik = np.sum(-lamb + Y * np.log(lamb) - gammaln(Y + 1))\n    return loglik\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.special import gammaln\n\ndef poisson_loglikelihood(lamb, Y):\n    if lamb &lt;= 0:\n        return -1e6\n    return np.sum(-lamb + Y * np.log(lamb) - gammaln(Y + 1))\n\nY = df[\"patents\"].values\n\nlambda_grid = np.linspace(0.1, 10, 200)\n\nloglik_vals = [poisson_loglikelihood(l, Y) for l in lambda_grid]\n\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_grid, loglik_vals, label=\"Log-Likelihood\")\nplt.xlabel(r\"$\\lambda$\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Log-Likelihood Curve for Poisson Model\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\nfrom scipy.optimize import minimize_scalar\n\nY = df[\"patents\"].values\n\nresult = minimize_scalar(\n    lambda l: -poisson_loglikelihood(l, Y),\n    bounds=(0.1, 10), \n    method='bounded'\n)\n\nprint(\"Estimated λ (MLE):\", round(result.x, 4))\nprint(\"Maximum Log-Likelihood:\", round(-result.fun, 2))\nEstimated λ (MLE): 3.6847 Maximum Log-Likelihood: -3367.68\n\n\n\nUsing our hand-coded Poisson log-likelihood function and the scipy.optimize.minimize_scalar() method,\nwe estimated the average number of patents per firm (λ) that best fits the data.\n\nEstimated λ (MLE): 3.6847\n\nMaximum Log-Likelihood: -3367.68\n\nThis estimate maximizes the log-likelihood of observing the actual distribution of patents across firms,\nassuming a Poisson model. This λ will serve as the baseline for further regression modeling.\nWe now derive the maximum likelihood estimator (MLE) for λ analytically.\nRecall the log-likelihood function for the Poisson distribution:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative with respect to λ:\n\\[\n\\frac{d\\ell}{d\\lambda} = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n= -n + \\frac{1}{\\lambda} \\sum_{i=1}^{n} Y_i\n\\]\nSet the derivative equal to 0 and solve:\n\\[\n-n + \\frac{\\sum Y_i}{\\lambda} = 0 \\quad \\Rightarrow \\quad \\lambda = \\frac{1}{n} \\sum Y_i = \\bar{Y}\n\\]\nThus, the MLE for λ is simply the sample mean of the observed values:\n\\[\n\\hat{\\lambda}_{MLE} = \\bar{Y}\n\\]\nThis result makes intuitive sense: in a Poisson distribution, the mean equals the rate parameter (λ),\nso the best estimate of λ is just the average observed number of patents.\nfrom scipy.optimize import minimize_scalar\n\nY = df[\"patents\"].values\n\nresult = minimize_scalar(\n    lambda l: -poisson_loglikelihood(l, Y),\n    bounds=(0.1, 10),\n    method='bounded'\n)\n\nprint(\"Estimated λ (MLE):\", round(result.x, 4))\nprint(\"Maximum Log-Likelihood:\", round(-result.fun, 2))\nEstimated λ (MLE): 3.6847 Maximum Log-Likelihood: -3367.68\nWe computed the MLE for λ by numerically optimizing our hand-coded log-likelihood function using\nscipy.optimize.minimize_scalar() in Python. The optimizer returned the following result:\n\nEstimated λ (MLE): 3.6847\n\nMaximum Log-Likelihood: -3367.68\n\nThis aligns with the theoretical result that the MLE of λ for a Poisson distribution is the sample mean.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\nX = df[[\"age\"]].copy()\nX[\"age_sq\"] = df[\"age\"] ** 2\nX = pd.get_dummies(X.join(df[\"region\"]), drop_first=True)\nX[\"iscustomer\"] = df[\"iscustomer\"]\nX = sm.add_constant(X)\n\nX_mat = X.to_numpy(dtype=float)\nY = df[\"patents\"].to_numpy(dtype=int)\n\ndef poisson_loglikelihood(beta, X, Y):\n    beta = np.asarray(beta)\n    eta = X @ beta\n    eta = np.clip(eta, -20, 20)             \n    lambda_i = np.exp(eta)\n    loglik = np.sum(-lambda_i + Y * np.log(lambda_i) - gammaln(Y + 1))\n    return -loglik\n\ninit_beta = np.zeros(X_mat.shape[1])\n\nresult = minimize(\n    fun=poisson_loglikelihood,\n    x0=init_beta,\n    args=(X_mat, Y),\n    method=\"BFGS\",\n    options={\"disp\": True}\n)\n\nbeta_hat = result.x\nhessian_inv = result.hess_inv \nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\ncoef_table = pd.DataFrame({\n    \"Variable\": X.columns,\n    \"Estimate\": np.round(beta_hat, 4),\n    \"Std. Error\": np.round(standard_errors, 4)\n})\n\nprint(coef_table)\n     Current function value: 3258.072164\n     Iterations: 14\n     Function evaluations: 759\n     Gradient evaluations: 83\n       Variable  Estimate  Std. Error\n0 const -0.5100 0.1930 1 age 0.1487 0.0145 2 age_sq -0.0030 0.0003 3 region_Northeast 0.0292 0.0468 4 region_Northwest -0.0176 0.0572 5 region_South 0.0566 0.0562 6 region_Southwest 0.0506 0.0496 7 iscustomer 0.2076 0.0329\n/opt/conda/lib/python3.11/site-packages/scipy/optimize/_minimize.py:708: OptimizeWarning:\n\nDesired error not necessarily achieved due to precision loss.\n\n\n\n\nWe estimated a Poisson regression model using maximum likelihood, where the log of the expected number of patents per firm is modeled as a linear function of firm characteristics.\nThe results indicate that:\n\nAge is positively associated with patent counts, but with a diminishing return (age squared is negative and significant).\nBlueprinty customers file significantly more patents, on average. The coefficient on iscustomer is +0.2076, with a standard error of 0.0329, indicating a statistically significant effect.\nRegion effects are small and mostly not statistically significant relative to the omitted base category.\n\nExponentiating the iscustomer coefficient gives:\n\\[\n\\exp(0.2076) \\approx 1.23\n\\]\nThis suggests that, holding other variables constant, Blueprinty customers are expected to have ~23% more patents than non-customers.\n\nimport statsmodels.api as sm\n\nX_fixed = X.astype(\"float\")\n\n\nglm_poisson = sm.GLM(df[\"patents\"], X_fixed, family=sm.families.Poisson())\nglm_results = glm_poisson.fit()\nprint(glm_results.summary())\n\n\n\n\nThe following shows the fitted Poisson regression results using Python’s built-in GLM() function:\n\n\n\n\nThe Poisson regression model estimates the expected number of patents awarded to a firm as a function of its characteristics. The key findings are:\n\nAge has a positive and statistically significant coefficient (0.1486), meaning that older firms tend to file more patents.\nHowever, the negative coefficient on age squared (-0.0030) indicates diminishing returns — the relationship is concave.\nRegion indicators are not statistically significant at the 5% level, suggesting little difference in patenting behavior across regions once other factors are controlled for.\nMost importantly, the coefficient on iscustomer is 0.2076 and highly significant (p &lt; 0.001).\nThis implies that, holding other factors constant, Blueprinty customers are associated with higher expected patent counts.\nSpecifically, exponentiating the coefficient gives:\n\\[\n\\exp(0.2076) \\approx 1.23\n\\]\nMeaning Blueprinty customers are expected to file approximately 23% more patents than non-customers, all else equal.\n\nThis result supports the claim that using Blueprinty’s software is associated with greater patenting activity.\nX_0 = X.copy()\nX_0[\"iscustomer\"] = 0\nX_0 = X_0.astype(float) \n\nX_1 = X.copy()\nX_1[\"iscustomer\"] = 1\nX_1 = X_1.astype(float)\n\ny_pred_0 = glm_results.predict(X_0)\ny_pred_1 = glm_results.predict(X_1)\n\navg_diff = (y_pred_1 - y_pred_0).mean()\nprint(\"Average predicted patent increase due to Blueprinty:\", round(avg_diff, 4))\nAverage predicted patent increase due to Blueprinty: 0.7928\n\n\n\nTo better understand the impact of Blueprinty software, we simulated a counterfactual scenario:\n\nWe predicted the number of patents for each firm assuming they do not use Blueprinty (set iscustomer = 0)\nThen we predicted the number assuming all firms use Blueprinty (iscustomer = 1)\n\nBy taking the difference in predicted patent counts for each firm and averaging, we estimate the average treatment effect.\nResult:\nIf all firms were Blueprinty customers, the average predicted number of patents would increase by 0.7928.\nThis suggests that Blueprinty’s software is associated with a meaningful increase in patent productivity, even after controlling for firm age and region."
  },
  {
    "objectID": "project/hw2/hw2_questions.html#airbnb-case-study",
    "href": "project/hw2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not"
  },
  {
    "objectID": "project/hw2/hw2_questions.html#data-reading-and-cleaning",
    "href": "project/hw2/hw2_questions.html#data-reading-and-cleaning",
    "title": "Poisson Regression Examples",
    "section": "1. Data Reading and Cleaning",
    "text": "1. Data Reading and Cleaning\n\nimport pandas as pd\n\ndf_airbnb = pd.read_csv(\"airbnb.csv\")\n\nbasic_info = df_airbnb.info()\nmissing_summary = df_airbnb.isnull().sum()\n\nhead_preview = df_airbnb.head()\n\nbasic_info_str = str(basic_info)\nmissing_summary_str = str(missing_summary)\nhead_preview_str = str(head_preview)\n\n(basic_info_str, missing_summary_str, head_preview_str)\n\ndf = pd.read_csv(\"airbnb.csv\")\n\nvars_required = [\n    \"number_of_reviews\",\n    \"price\",\n    \"room_type\",\n    \"bathrooms\",\n    \"bedrooms\",\n    \"review_scores_cleanliness\",\n    \"review_scores_location\",\n    \"review_scores_value\",\n    \"instant_bookable\"\n]\n\ndf_clean = df[vars_required].dropna()\n\ndf_clean[\"instant_bookable\"] = df_clean[\"instant_bookable\"].map({\"t\": 1, \"f\": 0})\n\nclean_shape = df_clean.shape\nmissing_check = df_clean.isnull().sum()\npreview = df_clean.head()\n\n(clean_shape, missing_check, preview)\n((30160, 9),\n number_of_reviews            0\n price                        0\n room_type                    0\n bathrooms                    0\n bedrooms                     0\n review_scores_cleanliness    0\n review_scores_location       0\n review_scores_value          0\n instant_bookable             0\n dtype: int64,\n    number_of_reviews  price        room_type  bathrooms  bedrooms  \\\n 0                150     59     Private room        1.0       1.0   \n 1                 20    230  Entire home/apt        1.0       0.0   \n 3                116     89  Entire home/apt        1.0       1.0   \n 5                 60    212  Entire home/apt        1.0       1.0   \n 6                 60    250  Entire home/apt        1.0       2.0   \n \n    review_scores_cleanliness  review_scores_location  review_scores_value  \\\n 0                        9.0                     9.0                  9.0   \n 1                        9.0                    10.0                  9.0   \n 3                        9.0                     9.0                  9.0   \n 5                        9.0                     9.0                  9.0   \n 6                       10.0                     9.0                 10.0   \n \n    instant_bookable  \n 0                 0  \n 1                 0  \n 3                 0  \n 5                 0  \n 6                 0  )\n\n🧹 Data Cleaning Summary\nBefore modeling, we performed basic data cleaning to ensure a consistent and usable dataset. Specifically:\nWe focused on variables relevant for predicting the number of reviews:\nnumber_of_reviews, price, room_type, bathrooms, bedrooms, review_scores_cleanliness, review_scores_location, review_scores_value, instant_bookable\nWe dropped rows with missing values in any of these variables, resulting in a cleaned dataset with 30,160 observations.\nThe variable instant_bookable was originally a string (“t”/“f”), and we converted it to a binary numeric variable (1/0).\nAll variables now have appropriate types for modeling:\nNumeric variables are of type float or int\nroom_type remains as a categorical variable, to be converted to dummy variables for regression\nThis cleaned dataset is now ready for exploratory data analysis and Poisson regression modeling."
  },
  {
    "objectID": "project/hw2/hw2_questions.html#exploratory-data-analysis",
    "href": "project/hw2/hw2_questions.html#exploratory-data-analysis",
    "title": "Poisson Regression Examples",
    "section": "2. Exploratory Data Analysis",
    "text": "2. Exploratory Data Analysis\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df_clean, x=\"number_of_reviews\", bins=50, kde=False, color=\"steelblue\")\nplt.title(\"Distribution of Number of Reviews\")\nplt.xlabel(\"Number of Reviews\")\nplt.ylabel(\"Count\")\nplt.xlim(0, 100)  \nplt.tight_layout()\nplt.show()\n\n\nDistribution of Number of Reviews\nThe number of reviews per listing is highly right-skewed. Most listings have relatively few reviews, with the majority concentrated between 0 and 10. A small number of listings have more than 50 reviews, creating a long tail.\nThis distribution suggests that a Poisson regression model is appropriate for modeling review counts. However, the presence of extreme values may need to be considered when interpreting model fit or influence."
  },
  {
    "objectID": "project/hw2/hw2_questions.html#modeling-review-counts-using-poisson-regression",
    "href": "project/hw2/hw2_questions.html#modeling-review-counts-using-poisson-regression",
    "title": "Poisson Regression Examples",
    "section": "3. Modeling Review Counts Using Poisson Regression",
    "text": "3. Modeling Review Counts Using Poisson Regression\n\nimport pandas as pd\nimport statsmodels.api as sm\n\nX = df_clean.copy()\n\nX = pd.get_dummies(X, columns=[\"room_type\"], drop_first=True)\n\nX[\"instant_bookable\"] = X[\"instant_bookable\"].astype(int)\n\nfeatures = [col for col in X.columns if col != \"number_of_reviews\"]\n\nX_design = sm.add_constant(X[features])\n\nY = X[\"number_of_reviews\"]\n\nX_design = X_design.astype(float)\n\npoisson_model = sm.GLM(Y, X_design, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\n\nsummary_text = poisson_results.summary().as_text()\nprint(summary_text)\n\nThe following table summarizes the fitted Poisson model coefficients:\n\n\nPoisson Regression Results\nWe modeled the number of reviews (as a proxy for bookings) using a Poisson regression. The model included key predictors like price, room type, review scores, and booking settings.\nKey findings include:\n\ninstant_bookable has a large and significant positive effect: listings that are instantly bookable are expected to receive about 39.7% more reviews.\nroom_type matters: compared to entire homes, shared rooms receive ~22% fewer reviews, and private rooms slightly fewer.\nCleanliness rating is positively associated with review count, while value and location scores are surprisingly negatively associated — possibly due to ratings bias or confounding.\nPrice is not a significant predictor in this model (p = 0.084).\n\nThese results suggest that ease of booking and property layout are key drivers of engagement on the platform."
  },
  {
    "objectID": "project/hw2/hw2_questions.html#estimated-impact-of-instant-bookable",
    "href": "project/hw2/hw2_questions.html#estimated-impact-of-instant-bookable",
    "title": "Poisson Regression Examples",
    "section": "4. Estimated Impact of Instant Bookable",
    "text": "4. Estimated Impact of Instant Bookable\n\nimport pandas as pd\nimport statsmodels.api as sm\n\ndf = pd.read_csv(\"airbnb.csv\")\n\nvars_required = [\n    \"number_of_reviews\", \"price\", \"room_type\", \"bathrooms\", \"bedrooms\",\n    \"review_scores_cleanliness\", \"review_scores_location\", \"review_scores_value\", \"instant_bookable\"\n]\ndf_clean = df[vars_required].dropna()\ndf_clean[\"instant_bookable\"] = df_clean[\"instant_bookable\"].map({\"t\": 1, \"f\": 0})\n\nX = pd.get_dummies(df_clean, columns=[\"room_type\"], drop_first=True)\nfeatures = [col for col in X.columns if col != \"number_of_reviews\"]\nX_design = sm.add_constant(X[features])\nX_design = X_design.astype(float)\n\npoisson_model = sm.GLM(Y, X_design, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\n\nX_0 = X_design.copy()\nX_1 = X_design.copy()\nX_0[\"instant_bookable\"] = 0\nX_1[\"instant_bookable\"] = 1\n\ny_pred_0 = poisson_results.predict(X_0.astype(float))\ny_pred_1 = poisson_results.predict(X_1.astype(float))\n\navg_diff = (y_pred_1 - y_pred_0).mean()\nprint(\"Average predicted review increase due to instant bookable:\", round(avg_diff, 4))\n\n\n4. Estimated Impact of Instant Bookable\nTo assess the causal effect of allowing instant booking, we simulated two scenarios:\n\nOne where all listings are not instantly bookable (instant_bookable = 0)\nAnother where all listings are instantly bookable (instant_bookable = 1)\n\nUsing our fitted Poisson model, we predicted the number of reviews for each listing under both scenarios and calculated the average difference.\nResult:\nIf all listings were set to be instantly bookable, each listing would receive an average of 7.80 additional reviews.\nThis highlights the strong association between booking convenience and customer engagement."
  },
  {
    "objectID": "project/hw2/hw2_questions.html#conclusion",
    "href": "project/hw2/hw2_questions.html#conclusion",
    "title": "Poisson Regression Examples",
    "section": "5. Conclusion",
    "text": "5. Conclusion\nIn this analysis, we used Airbnb listing data to explore the drivers of customer engagement, as proxied by the number of reviews. After data cleaning and exploratory analysis, we fit a Poisson regression model using listing features such as price, room type, review scores, and booking settings.\nOur findings indicate that:\n\nInstantly bookable listings are associated with significantly more reviews — approximately 7.8 additional reviews per listing, on average.\nRoom type has a strong effect: shared rooms receive significantly fewer reviews than entire homes.\nCleanliness scores are positively associated with engagement, whereas other review scores show mixed effects.\nPrice has a weak and statistically insignificant effect on review count in this model.\n\nThese results suggest that ease of booking and the physical configuration of a listing are key factors in driving guest interaction. Platform operators may consider promoting instantly bookable listings and encouraging hosts to improve service quality to increase visibility and engagement."
  },
  {
    "objectID": "project/project.html",
    "href": "project/project.html",
    "title": "Ethan’s project",
    "section": "",
    "text": "HW1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nEthan An\n\n\nMay 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nEthan An\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  }
]